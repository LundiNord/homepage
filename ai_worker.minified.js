import{pipeline,env,TextStreamer}from"/libs/transformerjs/transformers.js";import"/libs/transformerjs/ort-wasm-simd-threaded.jsep.mjs";let generator;async function checkForWebGPU(){try{if(!navigator.gpu)return!1;const e=await navigator.gpu.requestAdapter();if(!e)return!1;if(!await e.requestDevice())return!1}catch(e){return!1}return!0}async function loadModel(e="medium"){let t;"medium"===e?t="models/SmolLM2-360M-Instruct":"small"===e?t="models/SmolLM2-135M-Instruct":"big"===e&&(t="models/SmolLM2-1.7B-Instruct"),await checkForWebGPU()?(generator=await pipeline("text-generation",t,{dtype:"q4",device:"webgpu",version:"3.4.0"}),console.log("loaded model with webgpu")):(generator=await pipeline("text-generation",t,{dtype:"q4",version:"3.4.0"}),console.log("loaded model"))}env.allowRemoteModels=!0,env.allowLocalModels=!1,env.remoteHost="https://data.nyxnord.de",env.backends.onnx.wasm.wasmPaths="/libs/transformerjs/",addEventListener("message",(e=>{const{message:t,topic:r}=e.data;"input"===r?generateAnswer(t):"model"===r&&loadModel(t).then((e=>postMessage({message:"",topic:"loaded"})))}));let message=[{role:"system",content:"You are a helpful assistant."}],isGenerating=!1;async function generateAnswer(e){if(isGenerating||!e||!generator)return;isGenerating=!0;let t="";try{message.push({role:"user",content:e});const r=new TextStreamer(generator.tokenizer,{skip_prompt:!0,callback_function:e=>{t+=e,postMessage({message:t,topic:"output"})}});await generator(message,{max_new_tokens:200,temperature:.7,top_p:.9,do_sample:!0,streamer:r})}catch(e){console.error("Error generating response:",e)}finally{isGenerating=!1,message.push({role:"system",content:t})}}