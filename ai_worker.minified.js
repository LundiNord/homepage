import{pipeline,env,TextStreamer,InterruptableStoppingCriteria}from"/libs/transformerjs/transformers.js";import"/libs/transformerjs/ort-wasm-simd-threaded.jsep.mjs";let generator;env.allowRemoteModels=!0,env.allowLocalModels=!1,env.remoteHost="https://data.nyxnord.de",env.backends.onnx.wasm.wasmPaths="/libs/transformerjs/";let modelName,modelLoading=!1;async function checkForWebGPU(){try{if(!navigator.gpu)return!1;const e=await navigator.gpu.requestAdapter();if(!e)return!1;if(!await e.requestDevice())return!1}catch(e){return!1}return!0}async function loadModel(e="medium"){let t;if("medium"===e)t="models/SmolLM2-360M-Instruct",modelName="local";else if("small"===e)t="models/SmolLM2-135M-Instruct",modelName="local";else{if("big"!==e)return"gemma2-9b-it"===e||"llama-3.1-8b-instant"===e||"deepseek-r1-distill-llama-70b"===e?void(modelName=e):void console.error("Unknown model name:",e);t="models/SmolLM2-1.7B-Instruct",modelName="local"}modelLoading=!0,await checkForWebGPU()?(generator=await pipeline("text-generation",t,{dtype:"q4",device:"webgpu",version:"3.4.0",progress_callback:progressCallback}),console.log("loaded model with webgpu")):(generator=await pipeline("text-generation",t,{dtype:"q4",version:"3.4.0",progress_callback:progressCallback}),console.log("loaded model"),modelLoading=!1)}const progressCallback=e=>{postMessage({message:Math.floor(e.progress),topic:"progress"})};addEventListener("message",(e=>{const{message:t,topic:o}=e.data;if("input"===o)generateAnswer(t);else if("model"===o){if(modelLoading)return;loadModel(t).then((e=>postMessage({message:"",topic:"loaded"})))}else"stop"===o&&stoppingCriteria.interrupt()}));let message=[{role:"system",content:"You are a helpful assistant."}],isGenerating=!1,stoppingCriteria=new InterruptableStoppingCriteria;async function generateAnswer(e){!isGenerating&&e&&(message.push({role:"user",content:e}),"local"===modelName?await generateLocalAnswer():"gemma2-9b-it"!==modelName&&"llama-3.1-8b-instant"!==modelName&&"deepseek-r1-distill-llama-70b"!==modelName||await callGroqAPI(modelName))}async function generateLocalAnswer(){if(!generator)return;isGenerating=!0;let e="";try{const t=new TextStreamer(generator.tokenizer,{skip_prompt:!0,callback_function:t=>{e+=t,postMessage({message:e,topic:"output"})}});await generator(message,{max_new_tokens:200,temperature:.7,top_p:.9,do_sample:!0,streamer:t,stoppingCriteria:stoppingCriteria})}catch(e){console.error("Error generating response:",e)}finally{isGenerating=!1,message.push({role:"system",content:e}),postMessage({message:e,topic:"output_done"})}}const groqKey="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";async function callGroqAPI(e="gemma2-9b-it"){isGenerating=!0;const t=await fetch("https://api.groq.com/openai/v1/chat/completions",{method:"POST",headers:{"Content-Type":"application/json",Authorization:`Bearer ${groqKey}`},body:JSON.stringify({messages:message,model:e,temperature:1,max_completion_tokens:500,top_p:1,stream:!0,stop:null})});if(!t.ok||!t.body)throw new Error(`Error: ${t.status} ${t.statusText}`);const o=t.body.getReader();let a="";try{for(;;){const{done:e,value:t}=await o.read();if(e)break;const r=(new TextDecoder).decode(t).split("\n").filter((e=>e.trim().startsWith("data: ")));for(const e of r){const t=e.substring(6);if("[DONE]"!==t)try{const e=JSON.parse(t),o=e.choices[0]?.delta?.content||"";o&&(a+=o,postMessage({message:a,topic:"output"}))}catch(e){console.error("Error parsing JSON:",e)}}}}catch(e){console.error("Stream reading error:",e)}finally{isGenerating=!1,message.push({role:"system",content:a}),postMessage({message:a,topic:"output_done"})}}